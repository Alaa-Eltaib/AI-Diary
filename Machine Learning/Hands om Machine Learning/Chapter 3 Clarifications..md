

# الفصل الثالث: توضيحات

> **هذا المستند يغطي المفاهيم الأساسية والكاملة لتقييم نماذج التصنيف**، بدءًا من أبسط صورها (**التصنيف الثنائي**) وحتى المهام المتقدمة (**التصنيف متعدد المخرجات**)، مع التركيز على **"لماذا"** و **"كيف"** نستخدم كل مقياس.

---

## القسم الأول: التصنيف الثنائي (Binary Classification)

أبسط وأشهر أنواع التصنيف، حيث يقوم النموذج باتخاذ قرار بين حالتين فقط (**إيجابي/سلبي**، **0/1**، **نعم/لا**).

لفهم التقييم، يجب أولاً فهم **النتائج الأربعة المحتملة** لأي توقع:

| الحالة الحقيقية       | التوقع (Prediction)     | النتيجة | الاسم التقني               |
|------------------------|-------------------------|---------|----------------------------|
| Positive (5)           | Positive (5)            | ✅      | **True Positive (TP)**     |
| Negative (Not-5)       | Negative (Not-5)        | ✅      | **True Negative (TN)**     |
| Positive (5)           | Negative (Not-5)        | ❌      | **False Negative (FN)**    |
| Negative (Not-5)       | Positive (5)            | ❌      | **False Positive (FP)**    |

---

## القسم الثاني: فخ الدقة (The Accuracy Trap)

المقياس الأسهل هو **Accuracy (الدقة)**، وهو ببساطة:  
> *"كم مرة كان النموذج على صواب؟"*

$$
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
$$

### لكن، لماذا يمكن أن تخدعنا Accuracy؟

تخيل مجموعة بيانات **غير متوازنة** (Imbalanced Data):

- **55,000** صورة "ليست 5" (Negative)  
- **5,000** صورة فقط "هي 5" (Positive)

نموذج **"غبي"** يتوقع دائمًا "Not-5":

| النتيجة | العدد   |
|--------|--------|
| TN     | 55,000 |
| FN     | 5,000  |
| TP     | 0      |
| FP     | 0      |

$$
\text{Accuracy} = \frac{0 + 55,000}{60,000} = \frac{55,000}{60,000} \approx 91.6\%
$$

**المشكلة:**  
حصلنا على دقة **91.6%**، لكن النموذج **فاشل تمامًا** ولم يتعلم التعرف على الرقم 5 على الإطلاق!

> **نحتاج إلى مقاييس أعمق** تكشف لنا "سلوك" النموذج الحقيقي.

---

## القسم الثالث: المقاييس الأساسية (The Core Metrics)

تُبنى هذه المقاييس مباشرة من (TP, FP, FN).

### 1. مصفوفة الالتباس (Confusion Matrix)

جدول يعرض النتائج الأربعة، وهو **أساس كل المقاييس القادمة**.

| Actual \\ Predicted       | **Positive** (توقع: 5) | **Negative** (توقع: Not-5) |
|---------------------------|------------------------|-----------------------------|
| **Positive** (الحقيقة: 5) | ✅ **TP**              | ❌ **FN**                   |
| **Negative** (الحقيقة: Not-5) | ❌ **FP**          | ✅ **TN**                   |

---

### 2. الدقة (Precision)

> **السؤال:** *"من كل المرات التي توقع فيها النموذج أنها Positive، كم مرة كان على صواب؟"*

- **التركيز:** جودة التوقعات الإيجابية.
- **المعادلة:**
$$
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
$$

#### متى يكون مهمًا؟
عندما تكون تكلفة **False Positive (FP)** عالية جدًا.

| المثال              | التوضيح                                                                 |
|---------------------|-------------------------------------------------------------------------|
| **فلتر السبام**     | لا نريد إرسال إيميل "هام" إلى الـ Spam (FP).                          |
| **تشخيص السرطان**   | لا نريد إخبار شخص سليم بأنه "مريض" (FP).                              |

> **Precision عالي** = النموذج **"حذر"** ولا يطلق إنذارات كاذبة بسهولة.

---

### 3. الاستدعاء (Recall) / الحساسية (Sensitivity)

> **السؤال:** *"من كل الحالات الـ Positive الحقيقية، كم واحدة استطاع النموذج اكتشافها؟"*

- **التركيز:** اكتمال التوقعات الإيجابية (عدم تفويت أي شيء).
- **المعادلة:**
$$
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
$$

#### متى يكون مهمًا؟
عندما تكون تكلفة **False Negative (FN)** عالية جدًا.

| المثال              | التوضيح                                                                 |
|---------------------|-------------------------------------------------------------------------|
| **كشف الاحتيال**    | تفويت عملية احتيال (FN) أسوأ من التحقيق في عملية سليمة (FP).          |
| **تشخيص السرطان**   | تفويت مريض حقيقي (FN) كارثة.                                           |

> **Recall عالي** = النموذج **"شامل"** ولا يفوّت حالات إيجابية.

---

### 4. مقياس F1 (F1 Score)

**المشكلة:**  
لا يمكننا الحصول على **Precision و Recall عاليين في نفس الوقت**.

| السلوك                   | التأثير                     |
|--------------------------|-----------------------------|
| نموذج حذر جدًا (Precision ↑) | يفوّت حالات (Recall ↓)     |
| نموذج جريء جدًا (Recall ↑)   | يخطئ في توقعات إيجابية (Precision ↓) |

**الحل:** **F1 Score** هو المتوسط التوافقي (Harmonic Mean) بينهما.

$$
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

> **لماذا المتوسط التوافقي؟**  
يعاقب النموذج بشدة إذا كان أحد المقياسين منخفضًا جدًا → يضمن **التوازن**.

---

## القسم الرابع: أهم مفهوم - العتبة (The Threshold)

هذا هو **"المفتاح السري"** للتحكم بسلوك النموذج.

### ما هي الـ Threshold؟

النماذج لا تُخرج قرارًا نهائيًا (0 أو 1) مباشرة، بل تُخرج **درجة ثقة (Score)**:

| Score | المعنى                              |
|-------|-------------------------------------|
| +3.5  | شبه متأكد أنها Positive            |
| +0.2  | أظن أنها Positive، لكن لست متأكدًا |
| -1.3  | أظن أنها Negative                  |
| -4.0  | شبه متأكد أنها Negative            |

**الـ Threshold** هو الحد الفاصل:

```python
if score >= Threshold  →  Predict "Positive"
if score <  Threshold  →  Predict "Negative"
```

(الافتراضي غالبًا = 0)

---

### كيف نستخدم الـ Threshold للتحكم؟

| Threshold         | السلوك         | التأثير                     |
|-------------------|----------------|-----------------------------|
| **عالية (مثل 2)** | حذر جدًا       | Precision ↑، Recall ↓       |
| **منخفضة (مثل -1)** | جريء جدًا     | Recall ↑، Precision ↓       |

> **الخلاصة:** لا يوجد Threshold "صحيح" واحد.  
نختاره بناءً على **تكلفة الخطأ** في التطبيق.

---

## القسم الخامس: منحنيات التقييم (Visualization Curves)

بدلاً من اختيار Threshold واحد، نرسم أداء النموذج عبر **كل الـ Thresholds**.

### 1. منحنى Precision-Recall (PR Curve)

- **Y-axis:** Precision  
- **X-axis:** Recall  
- **الهدف:** أقرب للزاوية العليا اليمنى (1,1)

### 2. منحنى ROC (Receiver Operating Characteristic)

- **Y-axis:** True Positive Rate (TPR) = Recall  
- **X-axis:** False Positive Rate (FPR) = $\frac{FP}{FP + TN}$  
- **الخط القطري:** نموذج عشوائي  
- **الهدف:** أقرب للزاوية العليا اليسرى (0,1)

#### مقياس ROC-AUC:
- **AUC = 1:** نموذج مثالي  
- **AUC = 0.5:** نموذج عشوائي

| متى نستخدم؟                     |
|---------------------------------|
| **PR Curve** → عندما نهتم بالـ Positives (بيانات غير متوازنة) |
| **ROC Curve** → عندما نهتم بالفصل بين الفئتين بشكل عام |

---

## القسم السادس: توسيع نطاق المشكلة (Beyond Binary)

### 1. التصنيف متعدد الفئات (Multiclass Classification)

- عينة واحدة → فئة واحدة فقط  
- مثال: تصنيف الأرقام من 0 إلى 9

#### الاستراتيجيات:

| الطريقة          | الفكرة                                      | المميزات                     |
|------------------|---------------------------------------------|------------------------------|
| **One-vs-Rest (OvR)** | N classifiers (كل فئة ضد الباقي)            | سريع، مفضل مع SGD            |
| **One-vs-One (OvO)**  | $N \times (N-1)/2$ classifiers              | مفيد مع SVM                  |

---

### 2. التصنيف متعدد العلامات (Multilabel Classification)

- عينة واحدة → أكثر من فئة  
- مثال: صورة بها وجوه → [Alice: ✅, Bob: ❌, Charlie: ✅]

#### التقييم:
- نحسب F1 لكل Label على حدة  
- ثم نأخذ المتوسط:

| النوع               | الوصف                                      |
|---------------------|-------------------------------------------|
| **Macro Average**   | كل Label له نفس الأهمية                   |
| **Weighted Average**| الأهمية حسب عدد العينات (يأخذ Imbalance في الاعتبار) |

---

### 3. التصنيف متعدد المخرجات (Multioutput Classification)

- تعميم للـ Multilabel  
- كل Label يمكن أن يكون Multiclass

#### مثال: Image Denoising
- Input: صورة 28x28 مشوشة  
- Output: 784 مخرج (كل بكسل قيمة من 0-255)

---

## القسم السابع: اعتبارات عملية وتحليل الأخطاء

### 1. تحليل الأخطاء (Error Analysis)

- **الهدف:** فهم **"لماذا"** يخطئ النموذج، وليس فقط "كم".
- **الطريقة:**
  1. احصل على Confusion Matrix (Multiclass)
  2. ابحث عن الأخطاء العالية (خارج القطر الرئيسي)
  3. مثال: خلط بين 3 و 8 → اجمع بيانات أكثر أو استخدم Data Augmentation

---

### 2. تحجيم البيانات (Feature Scaling)

- **المشكلة:** بعض الخوارزميات (SVM, SGD) حساسة لمقياس الـ Features
- **الحل:** `StandardScaler()` أو `MinMaxScaler()`
- **النتيجة:** تحسين كبير في الأداء (مثل من 86% إلى 90%)
- **ملحوظة:** الأشجار (Random Forest) لا تحتاج Scaling

---

## ملخص المقارنة النهائية

| نوع المهمة           | عدد الـ Labels | نوع قيم الـ Label         | مثال                     |
|-----------------------|----------------|---------------------------|--------------------------|
| Binary                | 1              | 0/1                       | كشف السبام              |
| Multiclass            | 1              | أكثر من فئتين             | MNIST (0-9)              |
| Multilabel            | أكثر من 1      | 0/1 لكل Label             | التعرف على الوجوه       |
| Multioutput           | أكثر من 1      | Multiclass لكل Label      | إزالة التشويش من الصور  |

---

## أهم الدروس المستفادة

| الدرس                            | لماذا هو مهم؟                                                                 |
|----------------------------------|-------------------------------------------------------------------------------|
| **Accuracy ليست كل شيء**         | مضللة مع البيانات غير المتوازنة                                            |
| **افهم تكلفة الخطأ**             | هل FP أسوأ أم FN؟ → يحدد التركيز (Precision أم Recall)                       |
| **الـ Threshold أداتك**           | لضبط سلوك النموذج (حذر/جريء) ليتناسب مع التطبيق                             |
| **تحليل الأخطاء هو المفتاح**    | يوجهك للخطوة التالية (جمع بيانات، تحسين الـ Features، إلخ)                   |
| **افهم طبيعة المخرجات**         | أول خطوة لاختيار النموذج الصحيح وطريقة التقييم الصحيحة                     |

